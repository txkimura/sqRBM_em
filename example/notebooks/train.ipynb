{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext autotime\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "matplotlib.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "from models import sqRBM_em\n",
    "from models import RBM_em\n",
    "from utils import (\n",
    "    Discretizer,\n",
    "    kl_divergence,\n",
    "    get_project_dir, # returns: Path object of the project directory.\n",
    "    get_rng, # returns: Numpy RandomState object.\n",
    "    lr_exp_decay, # returns: The learning rate scaling factor\n",
    "    load_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_em(model):\n",
    "    TOL = 1e-16\n",
    "    prob_data = model.prob_data\n",
    "    p_model, Z = model.compute_p_model(prob_data)\n",
    "\n",
    "    qre = model.compute_qre(Z)\n",
    "\n",
    "    kld = 0\n",
    "    for i in prob_data.keys():\n",
    "        kld += prob_data[i] * (np.log(prob_data[i] + TOL) - np.log(p_model[i] + TOL))\n",
    "\n",
    "    return {\"qre\": qre, \"kld\": kld, \"print\": f\"qre = {qre}, kld = {kld}\"}\n",
    "\n",
    "def callback_gd(model):\n",
    "    TOL = 1e-16\n",
    "    prob_data = model.prob_data\n",
    "    p_model, Z = model.compute_p_model(prob_data)\n",
    "\n",
    "    kld = 0\n",
    "    for i in prob_data.keys():\n",
    "        kld += prob_data[i] * (np.log(prob_data[i] + TOL) - np.log(p_model[i] + TOL))\n",
    "\n",
    "    return {\"kld\": kld, \"print\": f\"kld = {kld}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def _binary_to_eigen(x):\n",
    "        \"\"\"\n",
    "        Convert bit values {0, 1} to corresponding spin values {+1, -1}.\n",
    "\n",
    "        :param x: Input array of values {0, 1}.\n",
    "\n",
    "        :returns: Output array of values {+1, -1}.\n",
    "        \"\"\"\n",
    "        return (1 - 2 * x).astype(np.int8)\n",
    "\n",
    "def bernoulli(p, v, M, n_visible, seed):\n",
    "    np.random.seed(seed)\n",
    "    bernoulli = 0\n",
    "    for i in range(M):\n",
    "        s = np.random.randint(2, size=n_visible)\n",
    "        d = distance.hamming(list(v), list(s)) * len(v)\n",
    "        bernoulli += (p ** (n_visible - d)) * ((1 - p) ** d)\n",
    "\n",
    "    return bernoulli / M\n",
    "\n",
    "def generate_bitstrings(n):\n",
    "    bitstrings = []\n",
    "    for x in range(2**n):\n",
    "        bitstring = format(x, f'0{n}b')\n",
    "        bits = [int(b) for b in bitstring]\n",
    "        bitstrings.append(bits)\n",
    "\n",
    "    return bitstrings\n",
    "\n",
    "def even_parity_probability_distribution(n):\n",
    "    bitstrings = generate_bitstrings(n)\n",
    "    entries = []\n",
    "\n",
    "    for bits in bitstrings:\n",
    "        count = sum(bits)\n",
    "        if count % 2 == 0:\n",
    "            entries.append(1)\n",
    "        else:\n",
    "            entries.append(0)\n",
    "\n",
    "    total = sum(entries)\n",
    "    probability = [entry / total for entry in entries]\n",
    "\n",
    "    return probability\n",
    "\n",
    "def cardinality_distribution(n):\n",
    "    bitstrings = generate_bitstrings(n)\n",
    "    entries = []\n",
    "\n",
    "    for bits in bitstrings:\n",
    "        count = sum(bits)\n",
    "        if count == n // 2:\n",
    "            entries.append(1)\n",
    "        else:\n",
    "            entries.append(0)\n",
    "\n",
    "    total = sum(entries)\n",
    "    probability = [entry / total for entry in entries]\n",
    "\n",
    "    return probability\n",
    "\n",
    "def on2_distribution(n, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    size = 2**n\n",
    "    probs = np.zeros(size)\n",
    "    \n",
    "    perm = np.random.permutation(size)\n",
    "    chosen_indices = perm[:n**2]\n",
    "    \n",
    "    probs[chosen_indices] = 1.0 / (n**2)\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# select situations\n",
    "situations = [101]\n",
    "\n",
    "start = 1\n",
    "end = 100\n",
    "\n",
    "for num_situation in situations:\n",
    "\n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # model params\n",
    "    params_path = f'../data/params/situation{num_situation}.json'\n",
    "    params = load_params(params_path)\n",
    "    print(params)\n",
    "    n_visible = params[\"n_visible\"]\n",
    "    n_hidden = params[\"n_hidden\"]\n",
    "    n_qubits = n_visible + n_hidden\n",
    "    n_epochs = params[\"n_epochs\"]\n",
    "    n_epochs_m = params[\"n_epochs_m\"]\n",
    "    learning_rate = params[\"learning_rate\"]\n",
    "    epsilon_em = params[\"epsilon_em\"]\n",
    "    epsilon_gd = params[\"epsilon_gd\"]\n",
    "    # seed = params[\"seed\"]\n",
    "    data_type = params[\"data_type\"]\n",
    "\n",
    "    # generate data distribution\n",
    "    prob_data = {}\n",
    "    for i in range(2**n_visible):\n",
    "        if data_type == 'bernoulli':\n",
    "            V_data = np.array(Discretizer.int_to_bit_vector(i, n_visible))\n",
    "            prob_data[i] = bernoulli(0.9, V_data, 8, n_visible, seed=0)\n",
    "        if data_type == 'even_parity':\n",
    "            prob_data[i] = even_parity_probability_distribution(n_visible)[i]\n",
    "        if data_type == 'cardinality':\n",
    "            prob_data[i] = cardinality_distribution(n_visible)[i]\n",
    "        if data_type == 'on2':\n",
    "            prob_data[i] = on2_distribution(n_visible, seed=0)[i]\n",
    "\n",
    "    print('prob_data', prob_data)\n",
    "    print('prob_data_sum', sum(prob_data.values()))\n",
    "\n",
    "    expected_value_V = np.zeros((1, n_visible))\n",
    "    for i in prob_data.keys():\n",
    "        V_data = np.array(Discretizer.int_to_bit_vector(i, n_visible)).reshape(1, -1)\n",
    "        V_data = _binary_to_eigen(V_data)\n",
    "        expected_value_V += prob_data[i] * V_data\n",
    "\n",
    "    print('expected_value_V', expected_value_V)\n",
    "\n",
    "    for time in range(start, end + 1):\n",
    "        print('time', time)\n",
    "\n",
    "        W_init = (np.random.rand(n_visible, n_hidden) - 0.5) * 10\n",
    "        print('W_init', W_init)\n",
    "        b_init = (np.random.rand(n_qubits) - 0.5) * 10\n",
    "        print('b_init', b_init)\n",
    "        Gamma_init = np.concatenate((np.zeros(n_visible), (np.random.rand(n_hidden) - 0.5) * 10))\n",
    "        print('Gamma_init', Gamma_init)\n",
    "\n",
    "        # model training\n",
    "        model_sqRBM_em = sqRBM_em(\n",
    "            prob_data=prob_data,\n",
    "            expected_value_V=expected_value_V,\n",
    "            n_visible=n_visible,\n",
    "            n_hidden=n_hidden,\n",
    "            W_init=W_init,\n",
    "            b_init=b_init,\n",
    "            Gamma_init=Gamma_init,\n",
    "            # Gamma=1,\n",
    "            B_freeze=1,\n",
    "            beta_initial=1,\n",
    "            seed=seed,\n",
    "        )\n",
    "        model_sqRBM_em.train_em(\n",
    "            n_epochs=n_epochs,\n",
    "            n_epochs_m=n_epochs_m,\n",
    "            learning_rate=learning_rate,\n",
    "            epsilon=epsilon_em,\n",
    "            callback=callback_em,\n",
    "        )\n",
    "\n",
    "        model_sqRBM_gd = sqRBM_em(\n",
    "            prob_data=prob_data,\n",
    "            expected_value_V=expected_value_V,\n",
    "            n_visible=n_visible,\n",
    "            n_hidden=n_hidden,\n",
    "            W_init=W_init,\n",
    "            b_init=b_init,\n",
    "            Gamma_init=Gamma_init,\n",
    "            # Gamma=1,\n",
    "            B_freeze=1,\n",
    "            beta_initial=1,\n",
    "            seed=seed,\n",
    "        )\n",
    "        model_sqRBM_gd.train_gd(\n",
    "            n_epochs=n_epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            epsilon=epsilon_gd,\n",
    "            callback=callback_gd,\n",
    "        )\n",
    "\n",
    "        model_RBM_em = RBM_em(\n",
    "            prob_data=prob_data,\n",
    "            expected_value_V=expected_value_V,\n",
    "            n_visible=n_visible,\n",
    "            n_hidden=n_hidden,\n",
    "            W_init=W_init,\n",
    "            b_init=b_init,\n",
    "            Gamma_init=Gamma_init,\n",
    "            B_freeze=1,\n",
    "            beta_initial=1,\n",
    "            seed=seed,\n",
    "        )\n",
    "        model_RBM_em.train_em(\n",
    "            n_epochs=n_epochs,\n",
    "            n_epochs_m=n_epochs_m,\n",
    "            learning_rate=learning_rate,\n",
    "            epsilon=epsilon_em,\n",
    "            callback=callback_em,\n",
    "        )\n",
    "\n",
    "        model_RBM_gd = RBM_em(\n",
    "            prob_data=prob_data,\n",
    "            expected_value_V=expected_value_V,\n",
    "            n_visible=n_visible,\n",
    "            n_hidden=n_hidden,\n",
    "            W_init=W_init,\n",
    "            b_init=b_init,\n",
    "            Gamma_init=Gamma_init,\n",
    "            B_freeze=1,\n",
    "            beta_initial=1,\n",
    "            seed=seed,\n",
    "        )\n",
    "        model_RBM_gd.train_gd(\n",
    "            n_epochs=n_epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            epsilon=epsilon_gd,\n",
    "            callback=callback_gd,\n",
    "        )\n",
    "\n",
    "        # save results\n",
    "        kld_em_quantum_epoch_m = [x[\"kld\"] for x in model_sqRBM_em.callback_history_epoch_m]\n",
    "        kld_emq_epoch_m = {'kld_emq_epoch_m': kld_em_quantum_epoch_m}\n",
    "        kld_em_quantum_epoch = [x[\"kld\"] for x in model_sqRBM_em.callback_history_epoch]\n",
    "        kld_emq_epoch = {'kld_emq_epoch': kld_em_quantum_epoch}\n",
    "\n",
    "        # qre_em_quantum_epoch_m = [x[\"qre\"] for x in model_sqRBM_em.callback_history_epoch_m]\n",
    "        # qre_emq_epoch_m = {'qre_emq_epoch_m': qre_em_quantum_epoch_m}\n",
    "        # qre_em_quantum_epoch = [x[\"qre\"] for x in model_sqRBM_em.callback_history_epoch]\n",
    "        # qre_emq_epoch = {'qre_emq_epoch': qre_em_quantum_epoch}\n",
    "\n",
    "        kld_gd_quantum = [x[\"kld\"] for x in model_sqRBM_gd.callback_history]\n",
    "        kld_gdq = {'kld_gdq': kld_gd_quantum}\n",
    "\n",
    "        kld_em_classical_epoch_m = [x[\"kld\"] for x in model_RBM_em.callback_history_epoch_m]\n",
    "        kld_emc_epoch_m = {'kld_emc_epoch_m': kld_em_classical_epoch_m}\n",
    "        kld_em_classical_epoch = [x[\"kld\"] for x in model_RBM_em.callback_history_epoch]\n",
    "        kld_emc_epoch = {'kld_emc_epoch': kld_em_classical_epoch}\n",
    "\n",
    "        # qre_em_classical_epoch_m = [x[\"qre\"] for x in model_RBM_em.callback_history_epoch_m]\n",
    "        # qre_emc_epoch_m = {'qre_emc_epoch_m': qre_em_classical_epoch_m}\n",
    "        # qre_em_classical_epoch = [x[\"qre\"] for x in model_RBM_em.callback_history_epoch]\n",
    "        # qre_emc_epoch = {'qre_emc_epoch': qre_em_classical_epoch}\n",
    "\n",
    "        kld_gd_classical = [x[\"kld\"] for x in model_RBM_gd.callback_history]\n",
    "        kld_gdc = {'kld_gdc': kld_gd_classical}\n",
    "\n",
    "        for j in [kld_emq_epoch_m, kld_emq_epoch, kld_gdq, kld_emc_epoch_m, kld_emc_epoch, kld_gdc]:\n",
    "            save_dir = f'../data/output/results/situation{num_situation}/time{time}'\n",
    "            name = f'{list(j.keys())[0]}'\n",
    "            filename = f'{name}'\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            filepath = os.path.join(save_dir, filename)\n",
    "\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(j[name], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
